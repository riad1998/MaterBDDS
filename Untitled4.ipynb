{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNfvkRmqn72uMDobcSA4W0V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c3b13dd6e7ff4677b7323353cf6b0d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_57ee325898dd4ff687d2249928b432b2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_39251ebd8ad346e3b43f6b3750c8aa4c",
              "IPY_MODEL_14fd4196d1b54133866f95aac391875c"
            ]
          }
        },
        "57ee325898dd4ff687d2249928b432b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "39251ebd8ad346e3b43f6b3750c8aa4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9335b84ec1a94b2e8a9d3ebaec6107fb",
            "_dom_classes": [],
            "description": "train.txt: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 849548,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 849548,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ecb454975da4e5098a54a71758d0007"
          }
        },
        "14fd4196d1b54133866f95aac391875c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1ba3fb8ce4fe40e0b3691b69883606dc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 850k/850k [00:00&lt;00:00, 1.03MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a1d3315516b42cb94a0046e21b320a2"
          }
        },
        "9335b84ec1a94b2e8a9d3ebaec6107fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ecb454975da4e5098a54a71758d0007": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ba3fb8ce4fe40e0b3691b69883606dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a1d3315516b42cb94a0046e21b320a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c421a6779aaf4eb1b429f706395c38a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a94dcec2d1654949bc3516c98b4667ed",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e5f75db5ec5e44f99b830f4c77a27604",
              "IPY_MODEL_bb32493c6c5d472892917aece45ab5f1"
            ]
          }
        },
        "a94dcec2d1654949bc3516c98b4667ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5f75db5ec5e44f99b830f4c77a27604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_efa4717985f34b7b87641f4b791fa08f",
            "_dom_classes": [],
            "description": "validation.txt: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 103771,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 103771,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e4976308670343d494d026479eaf8af4"
          }
        },
        "bb32493c6c5d472892917aece45ab5f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_68f97b36310b42f39b1e8539f1d55654",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 104k/104k [00:00&lt;00:00, 307kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3106109ba57b410eae7268a5ffa6c169"
          }
        },
        "efa4717985f34b7b87641f4b791fa08f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e4976308670343d494d026479eaf8af4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68f97b36310b42f39b1e8539f1d55654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3106109ba57b410eae7268a5ffa6c169": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "140c4c78b6ec4a0b8f473a538acdb617": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_143602134b0440c59484483bc8d88ac5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b884168b37cc4bbf9c34f734910943b0",
              "IPY_MODEL_e364384df5ae4006940caab022b4d93b"
            ]
          }
        },
        "143602134b0440c59484483bc8d88ac5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b884168b37cc4bbf9c34f734910943b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_15fdd2f17f9f4a49be3ca208d38e153f",
            "_dom_classes": [],
            "description": "test.txt: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 106837,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 106837,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6fb0dfdfbb64437e878289050269468a"
          }
        },
        "e364384df5ae4006940caab022b4d93b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c322d4af7a2f4aaaaa3082c62ab88167",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 107k/107k [00:00&lt;00:00, 1.37MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e61e7123eb0742b49355e8f603fcf3e6"
          }
        },
        "15fdd2f17f9f4a49be3ca208d38e153f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6fb0dfdfbb64437e878289050269468a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c322d4af7a2f4aaaaa3082c62ab88167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e61e7123eb0742b49355e8f603fcf3e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riad1998/MaterBDDS/blob/master/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351,
          "referenced_widgets": [
            "c3b13dd6e7ff4677b7323353cf6b0d17",
            "57ee325898dd4ff687d2249928b432b2",
            "39251ebd8ad346e3b43f6b3750c8aa4c",
            "14fd4196d1b54133866f95aac391875c",
            "9335b84ec1a94b2e8a9d3ebaec6107fb",
            "2ecb454975da4e5098a54a71758d0007",
            "1ba3fb8ce4fe40e0b3691b69883606dc",
            "2a1d3315516b42cb94a0046e21b320a2",
            "c421a6779aaf4eb1b429f706395c38a7",
            "a94dcec2d1654949bc3516c98b4667ed",
            "e5f75db5ec5e44f99b830f4c77a27604",
            "bb32493c6c5d472892917aece45ab5f1",
            "efa4717985f34b7b87641f4b791fa08f",
            "e4976308670343d494d026479eaf8af4",
            "68f97b36310b42f39b1e8539f1d55654",
            "3106109ba57b410eae7268a5ffa6c169",
            "140c4c78b6ec4a0b8f473a538acdb617",
            "143602134b0440c59484483bc8d88ac5",
            "b884168b37cc4bbf9c34f734910943b0",
            "e364384df5ae4006940caab022b4d93b",
            "15fdd2f17f9f4a49be3ca208d38e153f",
            "6fb0dfdfbb64437e878289050269468a",
            "c322d4af7a2f4aaaaa3082c62ab88167",
            "e61e7123eb0742b49355e8f603fcf3e6"
          ]
        },
        "id": "ymmLP84E9jpS",
        "outputId": "806a65d6-cc2e-4329-b8f8-f410ee4f0bfe"
      },
      "source": [
        "try:\r\n",
        "    import google.colab\r\n",
        "    IN_COLAB = True\r\n",
        "except:\r\n",
        "    IN_COLAB = False\r\n",
        "\r\n",
        "if IN_COLAB:\r\n",
        "    ! wget https://raw.githubusercontent.com/hse-aml/natural-language-processing/master/setup_google_colab.py -O setup_google_colab.py\r\n",
        "    import setup_google_colab\r\n",
        "    setup_google_colab.setup_week2()\r\n",
        "\r\n",
        "import sys\r\n",
        "sys.path.append(\"..\")\r\n",
        "from common.download_utils import download_week2_resources\r\n",
        "\r\n",
        "download_week2_resources()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-11 20:58:13--  https://raw.githubusercontent.com/hse-aml/natural-language-processing/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1939 (1.9K) [text/plain]\n",
            "Saving to: â€˜setup_google_colab.pyâ€™\n",
            "\n",
            "setup_google_colab. 100%[===================>]   1.89K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-03-11 20:58:13 (21.4 MB/s) - â€˜setup_google_colab.pyâ€™ saved [1939/1939]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3b13dd6e7ff4677b7323353cf6b0d17",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=849548.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c421a6779aaf4eb1b429f706395c38a7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=103771.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "140c4c78b6ec4a0b8f473a538acdb617",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=106837.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g2oZW42IQDq"
      },
      "source": [
        "\r\n",
        "def read_data(file_path):\r\n",
        "    tokens = []\r\n",
        "    tags = []\r\n",
        "    \r\n",
        "    tweet_tokens = []\r\n",
        "    tweet_tags = []\r\n",
        "    for line in open(file_path, encoding='utf-8'):\r\n",
        "        line = line.strip()\r\n",
        "        if not line:\r\n",
        "            if tweet_tokens:\r\n",
        "                tokens.append(tweet_tokens)\r\n",
        "                tags.append(tweet_tags)\r\n",
        "            tweet_tokens = []\r\n",
        "            tweet_tags = []\r\n",
        "        else:\r\n",
        "            token, tag = line.split()\r\n",
        "            # Replace all urls with <URL> token\r\n",
        "            # Replace all users with <USR> token\r\n",
        "\r\n",
        "            if token.startswith('@') == True:\r\n",
        "                token = '<USR>'\r\n",
        "            elif (token.startswith('http://') == True) or (token.startswith('https://') == True):\r\n",
        "                token = '<URL>'\r\n",
        "            \r\n",
        "            tweet_tokens.append(token)\r\n",
        "            tweet_tags.append(tag)\r\n",
        "            \r\n",
        "    return tokens, tags"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwYc0uq7J-1L"
      },
      "source": [
        "train_tokens, train_tags = read_data('data/train.txt')\r\n",
        "validation_tokens, validation_tags = read_data('data/validation.txt')\r\n",
        "test_tokens, test_tags = read_data('data/test.txt')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GIDIjqGKPxD",
        "outputId": "e4b4a62d-caba-47db-f4ab-20db3c454216"
      },
      "source": [
        "for i in range(3):\r\n",
        "    for token, tag in zip(train_tokens[i], train_tags[i]):\r\n",
        "        print('%s\\t%s' % (token, tag))\r\n",
        "    print()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RT\tO\n",
            "<USR>\tO\n",
            ":\tO\n",
            "Online\tO\n",
            "ticket\tO\n",
            "sales\tO\n",
            "for\tO\n",
            "Ghostland\tB-musicartist\n",
            "Observatory\tI-musicartist\n",
            "extended\tO\n",
            "until\tO\n",
            "6\tO\n",
            "PM\tO\n",
            "EST\tO\n",
            "due\tO\n",
            "to\tO\n",
            "high\tO\n",
            "demand\tO\n",
            ".\tO\n",
            "Get\tO\n",
            "them\tO\n",
            "before\tO\n",
            "they\tO\n",
            "sell\tO\n",
            "out\tO\n",
            "...\tO\n",
            "\n",
            "Apple\tB-product\n",
            "MacBook\tI-product\n",
            "Pro\tI-product\n",
            "A1278\tI-product\n",
            "13.3\tI-product\n",
            "\"\tI-product\n",
            "Laptop\tI-product\n",
            "-\tI-product\n",
            "MD101LL/A\tI-product\n",
            "(\tO\n",
            "June\tO\n",
            ",\tO\n",
            "2012\tO\n",
            ")\tO\n",
            "-\tO\n",
            "Full\tO\n",
            "read\tO\n",
            "by\tO\n",
            "eBay\tB-company\n",
            "<URL>\tO\n",
            "<URL>\tO\n",
            "\n",
            "Happy\tO\n",
            "Birthday\tO\n",
            "<USR>\tO\n",
            "!\tO\n",
            "May\tO\n",
            "Allah\tB-person\n",
            "s.w.t\tO\n",
            "bless\tO\n",
            "you\tO\n",
            "with\tO\n",
            "goodness\tO\n",
            "and\tO\n",
            "happiness\tO\n",
            ".\tO\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Imb5gqqALLaq"
      },
      "source": [
        "from collections import defaultdict"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "134DiUifLMzS"
      },
      "source": [
        "def build_dict(tokens_or_tags, special_tokens):\r\n",
        "    \"\"\"\r\n",
        "        tokens_or_tags: a list of lists of tokens or tags\r\n",
        "        special_tokens: some special tokens\r\n",
        "    \"\"\"\r\n",
        "    # Create a dictionary with default value 0\r\n",
        "    tok2idx = defaultdict(lambda: 0)\r\n",
        "    idx2tok = []\r\n",
        "    \r\n",
        "    # Create mappings from tokens (or tags) to indices and vice versa.\r\n",
        "    # At first, add special tokens (or tags) to the dictionaries.\r\n",
        "    # The first special token must have index 0.\r\n",
        "    \r\n",
        "    # Mapping tok2idx should contain each token or tag only once. \r\n",
        "    # To do so, you should:\r\n",
        "    # 1. extract unique tokens/tags from the tokens_or_tags variable, which is not\r\n",
        "    #    occur in special_tokens (because they could have non-empty intersection)\r\n",
        "    # 2. index them (for example, you can add them into the list idx2tok\r\n",
        "    # 3. for each token/tag save the index into tok2idx).\r\n",
        "    idx = 0\r\n",
        "    for token in special_tokens:\r\n",
        "        idx2tok.append(token)\r\n",
        "        tok2idx[token] = idx\r\n",
        "        idx += 1\r\n",
        "\r\n",
        "    for token_list in tokens_or_tags:\r\n",
        "        for token in token_list:\r\n",
        "            if token not in tok2idx:\r\n",
        "                idx2tok.append(token)\r\n",
        "                tok2idx[token] = idx\r\n",
        "                idx += 1\r\n",
        "\r\n",
        "    return tok2idx, idx2tok"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEQXCJkLOWuk"
      },
      "source": [
        "special_tokens = ['<UNK>', '<PAD>']\r\n",
        "special_tags = ['O']\r\n",
        "\r\n",
        "# Create dictionaries \r\n",
        "token2idx, idx2token = build_dict(train_tokens + validation_tokens, special_tokens)\r\n",
        "tag2idx, idx2tag = build_dict(train_tags, special_tags)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ispPmDTVOpwT"
      },
      "source": [
        "def words2idxs(tokens_list):\r\n",
        "    return [token2idx[word] for word in tokens_list]\r\n",
        "\r\n",
        "def tags2idxs(tags_list):\r\n",
        "    return [tag2idx[tag] for tag in tags_list]\r\n",
        "\r\n",
        "def idxs2words(idxs):\r\n",
        "    return [idx2token[idx] for idx in idxs]\r\n",
        "\r\n",
        "def idxs2tags(idxs):\r\n",
        "    return [idx2tag[idx] for idx in idxs]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2d61pMNOtPT"
      },
      "source": [
        "def batches_generator(batch_size, tokens, tags,\r\n",
        "                      shuffle=True, allow_smaller_last_batch=True):\r\n",
        "    \"\"\"Generates padded batches of tokens and tags.\"\"\"\r\n",
        "    \r\n",
        "    n_samples = len(tokens)\r\n",
        "    if shuffle:\r\n",
        "        order = np.random.permutation(n_samples)\r\n",
        "    else:\r\n",
        "        order = np.arange(n_samples)\r\n",
        "\r\n",
        "    n_batches = n_samples // batch_size\r\n",
        "    if allow_smaller_last_batch and n_samples % batch_size:\r\n",
        "        n_batches += 1\r\n",
        "\r\n",
        "    for k in range(n_batches):\r\n",
        "        batch_start = k * batch_size\r\n",
        "        batch_end = min((k + 1) * batch_size, n_samples)\r\n",
        "        current_batch_size = batch_end - batch_start\r\n",
        "        x_list = []\r\n",
        "        y_list = []\r\n",
        "        max_len_token = 0\r\n",
        "        for idx in order[batch_start: batch_end]:\r\n",
        "            x_list.append(words2idxs(tokens[idx]))\r\n",
        "            y_list.append(tags2idxs(tags[idx]))\r\n",
        "            max_len_token = max(max_len_token, len(tags[idx]))\r\n",
        "            \r\n",
        "        # Fill in the data into numpy nd-arrays filled with padding indices.\r\n",
        "        x = np.ones([current_batch_size, max_len_token], dtype=np.int32) * token2idx['<PAD>']\r\n",
        "        y = np.ones([current_batch_size, max_len_token], dtype=np.int32) * tag2idx['O']\r\n",
        "        lengths = np.zeros(current_batch_size, dtype=np.int32)\r\n",
        "        for n in range(current_batch_size):\r\n",
        "            utt_len = len(x_list[n])\r\n",
        "            x[n, :utt_len] = x_list[n]\r\n",
        "            lengths[n] = utt_len\r\n",
        "            y[n, :utt_len] = y_list[n]\r\n",
        "        yield x, y, lengths"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFeyB3jwSJAF"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmb2idVBSuSg"
      },
      "source": [
        "class BiLSTMModel():\r\n",
        "    pass"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FS0HoI7Sy8B"
      },
      "source": [
        "def declare_placeholders(self):\r\n",
        "    \"\"\"Specifies placeholders for the model.\"\"\"\r\n",
        "\r\n",
        "    # Placeholders for input and ground truth output.\r\n",
        "    self.input_batch = tf.placeholder(dtype=tf.int32, shape=[None, None], name='input_batch') \r\n",
        "    self.ground_truth_tags = tf.placeholder(dtype=tf.int32, shape=[None, None], name='ground_truth_tags')\r\n",
        "  \r\n",
        "    # Placeholder for lengths of the sequences.\r\n",
        "    self.lengths = tf.placeholder(dtype=tf.int32, shape=[None], name='lengths') \r\n",
        "    \r\n",
        "    # Placeholder for a dropout keep probability. If we don't feed\r\n",
        "    # a value for this placeholder, it will be equal to 1.0.\r\n",
        "    self.dropout_ph = tf.placeholder_with_default(tf.cast(1.0, tf.float32), shape=[])\r\n",
        "    \r\n",
        "    # Placeholder for a learning rate (tf.float32).\r\n",
        "    self.learning_rate_ph = tf.placeholder(dtype=tf.float32,shape=[],name='learning_rate_ph')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl6dVke7TdlJ"
      },
      "source": [
        "BiLSTMModel.__declare_placeholders = classmethod(declare_placeholders)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrrcy-3vTgYl"
      },
      "source": [
        "def build_layers(self, vocabulary_size, embedding_dim, n_hidden_rnn, n_tags):\r\n",
        "    \"\"\"Specifies bi-LSTM architecture and computes logits for inputs.\"\"\"\r\n",
        "    \r\n",
        "    # Create embedding variable (tf.Variable) with dtype tf.float32\r\n",
        "    initial_embedding_matrix = (np.random.randn(vocabulary_size, embedding_dim) / np.sqrt(embedding_dim))\r\n",
        "    embedding_matrix_variable =tf.Variable(dtype=tf.float32,initial_value=initial_embedding_matrix,name='embeddings_matrix') \r\n",
        "    \r\n",
        "    # Create RNN cells (for example, tf.nn.rnn_cell.BasicLSTMCell) with n_hidden_rnn number of units \r\n",
        "    # and dropout (tf.nn.rnn_cell.DropoutWrapper), initializing all *_keep_prob with dropout placeholder.\r\n",
        "    forward_cell =  tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.BasicLSTMCell(num_units=n_hidden_rnn),input_keep_prob=self.dropout_ph, output_keep_prob=self.dropout_ph, state_keep_prob=self.dropout_ph)\r\n",
        "    backward_cell = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.BasicLSTMCell(num_units=n_hidden_rnn),input_keep_prob=self.dropout_ph, output_keep_prob=self.dropout_ph, state_keep_prob=self.dropout_ph)\r\n",
        "\r\n",
        "    # Look up embeddings for self.input_batch (tf.nn.embedding_lookup).\r\n",
        "    # Shape: [batch_size, sequence_len, embedding_dim].\r\n",
        "    embeddings = tf.nn.embedding_lookup(embedding_matrix_variable,self.input_batch)\r\n",
        "    \r\n",
        "    # Pass them through Bidirectional Dynamic RNN (tf.nn.bidirectional_dynamic_rnn).\r\n",
        "    # Shape: [batch_size, sequence_len, 2 * n_hidden_rnn]. \r\n",
        "    # Also don't forget to initialize sequence_length as self.lengths and dtype as tf.float32.\r\n",
        "    (rnn_output_fw, rnn_output_bw), _ = tf.nn.bidirectional_dynamic_rnn(forward_cell,backward_cell,inputs=embeddings,sequence_length=self.lengths,dtype=tf.float32)\r\n",
        "    rnn_output = tf.concat([rnn_output_fw, rnn_output_bw], axis=2)\r\n",
        "\r\n",
        "    # Dense layer on top.\r\n",
        "    # Shape: [batch_size, sequence_len, n_tags].   \r\n",
        "    self.logits = tf.layers.dense(rnn_output, n_tags, activation=None)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd7n94z5T5TF"
      },
      "source": [
        "BiLSTMModel.__build_layers = classmethod(build_layers)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq_oa2_TUGhP"
      },
      "source": [
        "def compute_predictions(self):\r\n",
        "    \"\"\"Transforms logits to probabilities and finds the most probable tags.\"\"\"\r\n",
        "    \r\n",
        "    # Create softmax (tf.nn.softmax) function\r\n",
        "    softmax_output = tf.nn.softmax(self.logits)\r\n",
        "    \r\n",
        "    # Use argmax (tf.argmax) to get the most probable tags\r\n",
        "    # Don't forget to set axis=-1\r\n",
        "    # otherwise argmax will be calculated in a wrong way\r\n",
        "    self.predictions = tf.argmax(softmax_output,axis=-1)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfD72FH3UKhs"
      },
      "source": [
        "BiLSTMModel.__compute_predictions = classmethod(compute_predictions)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi-nTObTUOUA"
      },
      "source": [
        "def compute_loss(self, n_tags, PAD_index):\r\n",
        "    \"\"\"Computes masked cross-entopy loss with logits.\"\"\"\r\n",
        "    \r\n",
        "    # Create cross entropy function function (tf.nn.softmax_cross_entropy_with_logits)\r\n",
        "    ground_truth_tags_one_hot = tf.one_hot(self.ground_truth_tags, n_tags)\r\n",
        "    loss_tensor = tf.nn.softmax_cross_entropy_with_logits(labels=ground_truth_tags_one_hot,logits=self.logits)\r\n",
        "    \r\n",
        "    mask = tf.cast(tf.not_equal(loss_tensor, PAD_index), tf.float32)\r\n",
        "    # Create loss function which doesn't operate with <PAD> tokens (tf.reduce_mean)\r\n",
        "    # Be careful that the argument of tf.reduce_mean should be\r\n",
        "    # multiplication of mask and loss_tensor.\r\n",
        "    self.loss = tf.reduce_mean(tf.multiply(loss_tensor,mask))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjR06yUIUs1y"
      },
      "source": [
        "BiLSTMModel.__compute_loss = classmethod(compute_loss)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vtu_MMx0Uvtk"
      },
      "source": [
        "def perform_optimization(self):\r\n",
        "    \"\"\"Specifies the optimizer and train_op for the model.\"\"\"\r\n",
        "    \r\n",
        "    # Create an optimizer (tf.train.AdamOptimizer)\r\n",
        "    self.optimizer =  tf.train.AdamOptimizer(self.learning_rate_ph)\r\n",
        "    self.grads_and_vars = self.optimizer.compute_gradients(self.loss)\r\n",
        "    \r\n",
        "    # Gradient clipping (tf.clip_by_norm) for self.grads_and_vars\r\n",
        "    # Pay attention that you need to apply this operation only for gradients \r\n",
        "    # because self.grads_and_vars contains also variables.\r\n",
        "    # list comprehension might be useful in this case.\r\n",
        "    clip_norm = tf.cast(1.0, tf.float32)\r\n",
        "    self.grads_and_vars =  [(None, var) if grad is None else (tf.clip_by_norm(grad, clip_norm), var) for grad, var in self.grads_and_vars]    \r\n",
        "    self.train_op = self.optimizer.apply_gradients(self.grads_and_vars)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7QcZr1dVDJ0"
      },
      "source": [
        "BiLSTMModel.__perform_optimization = classmethod(perform_optimization)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ0qekEgVQ9P"
      },
      "source": [
        "def init_model(self, vocabulary_size, n_tags, embedding_dim, n_hidden_rnn, PAD_index):\r\n",
        "    self.__declare_placeholders()\r\n",
        "    self.__build_layers(vocabulary_size, embedding_dim, n_hidden_rnn, n_tags)\r\n",
        "    self.__compute_predictions()\r\n",
        "    self.__compute_loss(n_tags, PAD_index)\r\n",
        "    self.__perform_optimization()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPRhFXqkVVMB"
      },
      "source": [
        "BiLSTMModel.__init__ = classmethod(init_model)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0Xb8_pAVXbp"
      },
      "source": [
        "def train_on_batch(self, session, x_batch, y_batch, lengths, learning_rate, dropout_keep_probability):\r\n",
        "    feed_dict = {self.input_batch: x_batch,\r\n",
        "                 self.ground_truth_tags: y_batch,\r\n",
        "                 self.learning_rate_ph: learning_rate,\r\n",
        "                 self.dropout_ph: dropout_keep_probability,\r\n",
        "                 self.lengths: lengths}\r\n",
        "    \r\n",
        "    session.run(self.train_op, feed_dict=feed_dict)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNuu_Jx-VjBv"
      },
      "source": [
        "BiLSTMModel.train_on_batch = classmethod(train_on_batch)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbZ1ry_bVr18"
      },
      "source": [
        "def predict_for_batch(self, session, x_batch, lengths):\r\n",
        "    feed_dict={self.input_batch:x_batch,self.lengths:lengths}\r\n",
        "    predictions=session.run(self.predictions,feed_dict=feed_dict)\r\n",
        "    return predictions"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWyEnOc7Vvh6"
      },
      "source": [
        "BiLSTMModel.predict_for_batch = classmethod(predict_for_batch)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bauFKoztV03H"
      },
      "source": [
        "from evaluation import precision_recall_f1"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVpQPRvIV-rN"
      },
      "source": [
        "\r\n",
        "def predict_tags(model, session, token_idxs_batch, lengths):\r\n",
        "    \"\"\"Performs predictions and transforms indices to tokens and tags.\"\"\"\r\n",
        "    \r\n",
        "    tag_idxs_batch = model.predict_for_batch(session, token_idxs_batch, lengths)\r\n",
        "    \r\n",
        "    tags_batch, tokens_batch = [], []\r\n",
        "    for tag_idxs, token_idxs in zip(tag_idxs_batch, token_idxs_batch):\r\n",
        "        tags, tokens = [], []\r\n",
        "        for tag_idx, token_idx in zip(tag_idxs, token_idxs):\r\n",
        "            tags.append(idx2tag[tag_idx])\r\n",
        "            tokens.append(idx2token[token_idx])\r\n",
        "        tags_batch.append(tags)\r\n",
        "        tokens_batch.append(tokens)\r\n",
        "    return tags_batch, tokens_batch\r\n",
        "    \r\n",
        "    \r\n",
        "def eval_conll(model, session, tokens, tags, short_report=True):\r\n",
        "    \"\"\"Computes NER quality measures using CONLL shared task script.\"\"\"\r\n",
        "    \r\n",
        "    y_true, y_pred = [], []\r\n",
        "    for x_batch, y_batch, lengths in batches_generator(1, tokens, tags):\r\n",
        "        tags_batch, tokens_batch = predict_tags(model, session, x_batch, lengths)\r\n",
        "        if len(x_batch[0]) != len(tags_batch[0]):\r\n",
        "            raise Exception(\"Incorrect length of prediction for the input, \"\r\n",
        "                            \"expected length: %i, got: %i\" % (len(x_batch[0]), len(tags_batch[0])))\r\n",
        "        predicted_tags = []\r\n",
        "        ground_truth_tags = []\r\n",
        "        for gt_tag_idx, pred_tag, token in zip(y_batch[0], tags_batch[0], tokens_batch[0]): \r\n",
        "            if token != '<PAD>':\r\n",
        "                ground_truth_tags.append(idx2tag[gt_tag_idx])\r\n",
        "                predicted_tags.append(pred_tag)\r\n",
        "\r\n",
        "        # We extend every prediction and ground truth sequence with 'O' tag\r\n",
        "        # to indicate a possible end of entity.\r\n",
        "        y_true.extend(ground_truth_tags + ['O'])\r\n",
        "        y_pred.extend(predicted_tags + ['O'])\r\n",
        "        \r\n",
        "    results = precision_recall_f1(y_true, y_pred, print_results=True, short_report=short_report)\r\n",
        "    return results"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VZqOHCqWLOj"
      },
      "source": [
        "from tensorflow.python.framework import ops\r\n",
        "ops.reset_default_graph()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOdkjip8WMtb",
        "outputId": "ea9859a3-fbe4-435b-98c6-1c40d4c3d1bf"
      },
      "source": [
        "len(idx2token)\r\n",
        "len(idx2tag)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2FRsevbWM1o",
        "outputId": "b6a4dfbf-52a2-4d5c-ac2e-8a74ea533fdd"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\r\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rW6hlFWGW7Wi",
        "outputId": "9f92f52a-52c3-405b-d3ad-91d6b2dd5edf"
      },
      "source": [
        "tf.reset_default_graph()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "model = BiLSTMModel(len(idx2token), len(idx2tag), 200, 200, token2idx['<PAD>'])\r\n",
        "\r\n",
        " ######### YOUR CODE HERE #############\r\n",
        "\r\n",
        "batch_size = 32 ######### YOUR CODE HERE #############\r\n",
        "n_epochs = 4 ######### YOUR CODE HERE #############\r\n",
        "learning_rate = 0.005 ######### YOUR CODE HERE #############\r\n",
        "learning_rate_decay = np.sqrt(2)######### YOUR CODE HERE #############\r\n",
        "dropout_keep_probability = 0.5 ######### YOUR CODE HERE #############"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:702: UserWarning: `tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  warnings.warn(\"`tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMQvRhWeW-Ti",
        "outputId": "3ee873ee-08a9-480a-918f-41f6ea0e168f"
      },
      "source": [
        "sess = tf.Session()\r\n",
        "sess.run(tf.global_variables_initializer())\r\n",
        "\r\n",
        "print('Start training... \\n')\r\n",
        "for epoch in range(n_epochs):\r\n",
        "    # For each epoch evaluate the model on train and validation data\r\n",
        "    print('-' * 20 + ' Epoch {} '.format(epoch+1) + 'of {} '.format(n_epochs) + '-' * 20)\r\n",
        "    print('Train data evaluation:')\r\n",
        "    eval_conll(model, sess, train_tokens, train_tags, short_report=True)\r\n",
        "    print('Validation data evaluation:')\r\n",
        "    eval_conll(model, sess, validation_tokens, validation_tags, short_report=True)\r\n",
        "    \r\n",
        "    # Train the model\r\n",
        "    for x_batch, y_batch, lengths in batches_generator(batch_size, train_tokens, train_tags):\r\n",
        "        model.train_on_batch(sess, x_batch, y_batch, lengths, learning_rate, dropout_keep_probability)\r\n",
        "        \r\n",
        "    # Decaying the learning rate\r\n",
        "    learning_rate = learning_rate / learning_rate_decay\r\n",
        "    \r\n",
        "print('...training finished.')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start training... \n",
            "\n",
            "-------------------- Epoch 1 of 4 --------------------\n",
            "Train data evaluation:\n",
            "processed 105778 tokens with 4489 phrases; found: 77220 phrases; correct: 182.\n",
            "\n",
            "precision:  0.24%; recall:  4.05%; F1:  0.45\n",
            "\n",
            "Validation data evaluation:\n",
            "processed 12836 tokens with 537 phrases; found: 9400 phrases; correct: 14.\n",
            "\n",
            "precision:  0.15%; recall:  2.61%; F1:  0.28\n",
            "\n",
            "-------------------- Epoch 2 of 4 --------------------\n",
            "Train data evaluation:\n",
            "processed 105778 tokens with 4489 phrases; found: 2070 phrases; correct: 578.\n",
            "\n",
            "precision:  27.92%; recall:  12.88%; F1:  17.62\n",
            "\n",
            "Validation data evaluation:\n",
            "processed 12836 tokens with 537 phrases; found: 192 phrases; correct: 52.\n",
            "\n",
            "precision:  27.08%; recall:  9.68%; F1:  14.27\n",
            "\n",
            "-------------------- Epoch 3 of 4 --------------------\n",
            "Train data evaluation:\n",
            "processed 105778 tokens with 4489 phrases; found: 4485 phrases; correct: 2120.\n",
            "\n",
            "precision:  47.27%; recall:  47.23%; F1:  47.25\n",
            "\n",
            "Validation data evaluation:\n",
            "processed 12836 tokens with 537 phrases; found: 340 phrases; correct: 141.\n",
            "\n",
            "precision:  41.47%; recall:  26.26%; F1:  32.16\n",
            "\n",
            "-------------------- Epoch 4 of 4 --------------------\n",
            "Train data evaluation:\n",
            "processed 105778 tokens with 4489 phrases; found: 4804 phrases; correct: 3156.\n",
            "\n",
            "precision:  65.70%; recall:  70.31%; F1:  67.92\n",
            "\n",
            "Validation data evaluation:\n",
            "processed 12836 tokens with 537 phrases; found: 444 phrases; correct: 185.\n",
            "\n",
            "precision:  41.67%; recall:  34.45%; F1:  37.72\n",
            "\n",
            "...training finished.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhVdaAqCZsQB",
        "outputId": "a04d1d72-7ecc-426a-934c-26429bf452f1"
      },
      "source": [
        "print('-' * 20 + ' Train set quality: ' + '-' * 20)\r\n",
        "train_results = eval_conll(model, sess, train_tokens, train_tags, short_report=False)\r\n",
        "\r\n",
        "print('-' * 20 + ' Validation set quality: ' + '-' * 20)\r\n",
        "validation_results = eval_conll(model, sess, validation_tokens, validation_tags, short_report=False)\r\n",
        "\r\n",
        "print('-' * 20 + ' Test set quality: ' + '-' * 20)\r\n",
        "test_results = eval_conll(model, sess, test_tokens, test_tags, short_report=False)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------- Train set quality: --------------------\n",
            "processed 105778 tokens with 4489 phrases; found: 4567 phrases; correct: 3613.\n",
            "\n",
            "precision:  79.11%; recall:  80.49%; F1:  79.79\n",
            "\n",
            "\t     company: precision:   89.28%; recall:   90.67%; F1:   89.97; predicted:   653\n",
            "\n",
            "\t    facility: precision:   71.31%; recall:   83.12%; F1:   76.76; predicted:   366\n",
            "\n",
            "\t     geo-loc: precision:   80.69%; recall:   95.68%; F1:   87.55; predicted:  1181\n",
            "\n",
            "\t       movie: precision:   31.58%; recall:   17.65%; F1:   22.64; predicted:    38\n",
            "\n",
            "\t musicartist: precision:   60.55%; recall:   56.90%; F1:   58.67; predicted:   218\n",
            "\n",
            "\t       other: precision:   76.08%; recall:   84.02%; F1:   79.85; predicted:   836\n",
            "\n",
            "\t      person: precision:   84.13%; recall:   93.34%; F1:   88.50; predicted:   983\n",
            "\n",
            "\t     product: precision:   72.46%; recall:   62.89%; F1:   67.34; predicted:   276\n",
            "\n",
            "\t  sportsteam: precision:   54.55%; recall:    2.76%; F1:    5.26; predicted:    11\n",
            "\n",
            "\t      tvshow: precision:   60.00%; recall:    5.17%; F1:    9.52; predicted:     5\n",
            "\n",
            "-------------------- Validation set quality: --------------------\n",
            "processed 12836 tokens with 537 phrases; found: 401 phrases; correct: 181.\n",
            "\n",
            "precision:  45.14%; recall:  33.71%; F1:  38.59\n",
            "\n",
            "\t     company: precision:   64.29%; recall:   51.92%; F1:   57.45; predicted:    84\n",
            "\n",
            "\t    facility: precision:   41.94%; recall:   38.24%; F1:   40.00; predicted:    31\n",
            "\n",
            "\t     geo-loc: precision:   63.95%; recall:   48.67%; F1:   55.28; predicted:    86\n",
            "\n",
            "\t       movie: precision:    0.00%; recall:    0.00%; F1:    0.00; predicted:     2\n",
            "\n",
            "\t musicartist: precision:    7.69%; recall:    3.57%; F1:    4.88; predicted:    13\n",
            "\n",
            "\t       other: precision:   28.89%; recall:   32.10%; F1:   30.41; predicted:    90\n",
            "\n",
            "\t      person: precision:   38.03%; recall:   24.11%; F1:   29.51; predicted:    71\n",
            "\n",
            "\t     product: precision:   20.83%; recall:   14.71%; F1:   17.24; predicted:    24\n",
            "\n",
            "\t  sportsteam: precision:    0.00%; recall:    0.00%; F1:    0.00; predicted:     0\n",
            "\n",
            "\t      tvshow: precision:    0.00%; recall:    0.00%; F1:    0.00; predicted:     0\n",
            "\n",
            "-------------------- Test set quality: --------------------\n",
            "processed 13258 tokens with 604 phrases; found: 602 phrases; correct: 235.\n",
            "\n",
            "precision:  39.04%; recall:  38.91%; F1:  38.97\n",
            "\n",
            "\t     company: precision:   70.59%; recall:   42.86%; F1:   53.33; predicted:    51\n",
            "\n",
            "\t    facility: precision:   46.15%; recall:   38.30%; F1:   41.86; predicted:    39\n",
            "\n",
            "\t     geo-loc: precision:   68.94%; recall:   55.15%; F1:   61.28; predicted:   132\n",
            "\n",
            "\t       movie: precision:    0.00%; recall:    0.00%; F1:    0.00; predicted:     1\n",
            "\n",
            "\t musicartist: precision:   11.76%; recall:    7.41%; F1:    9.09; predicted:    17\n",
            "\n",
            "\t       other: precision:   36.08%; recall:   33.98%; F1:   35.00; predicted:    97\n",
            "\n",
            "\t      person: precision:   22.47%; recall:   49.04%; F1:   30.82; predicted:   227\n",
            "\n",
            "\t     product: precision:    5.41%; recall:    7.14%; F1:    6.15; predicted:    37\n",
            "\n",
            "\t  sportsteam: precision:    0.00%; recall:    0.00%; F1:    0.00; predicted:     1\n",
            "\n",
            "\t      tvshow: precision:    0.00%; recall:    0.00%; F1:    0.00; predicted:     0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}